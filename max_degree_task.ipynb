{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04116cac-3e0c-46bd-a71d-01a911029f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/lfesser/.conda/envs/borf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.nn import (\n",
    "    BatchNorm1d,\n",
    "    Embedding,\n",
    "    Linear,\n",
    "    ModuleList,\n",
    "    ReLU,\n",
    "    Sequential,\n",
    ")\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_networkx, from_networkx, to_dense_adj\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_add_pool #, global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3c44a4-6ddc-4c10-946f-6a43fba0e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_max_degree_graph(num_nodes: int, topology: str=\"complete\",\n",
    "                              random_features: str=\"gaussian\", feature_dim: int=1) -> Data:\n",
    "    assert num_nodes > 0\n",
    "    assert topology in [\"complete\", \"path\", \"cycle\", \"regular\", \"tree\", \"ER\"], \"Error: unknown topology\" # need to implement more\n",
    "    assert random_features in [\"gaussian\"], \"Error: unknown feature distribution\" # need to implement more\n",
    "    assert feature_dim > 0\n",
    "    \n",
    "    # create a networkx graph with the desired topology\n",
    "    if topology == \"complete\":\n",
    "        raw_graph = create_complete_graph(num_nodes)\n",
    "        \n",
    "    if topology == \"path\":\n",
    "        raw_graph = create_path_graph(num_nodes)\n",
    "        \n",
    "    if topology == \"cycle\":\n",
    "        raw_graph = create_cycle_graph(num_nodes)\n",
    "        \n",
    "    if topology == \"regular\":\n",
    "        raw_graph = create_4_regular_grid_graph(num_nodes, num_nodes)\n",
    "        \n",
    "    if topology == \"tree\":\n",
    "        raw_graph = create_binary_tree(num_nodes)\n",
    "        \n",
    "    if topology == \"ER\":\n",
    "        raw_graph = create_er_graph(num_nodes)\n",
    "        \n",
    "    # add random features from the desired distribution\n",
    "    if random_features == \"gaussian\":\n",
    "        attributed_graph = add_gaussian_node_features(raw_graph, feature_dim)\n",
    "    \n",
    "    # convert the networkx graph to pytorch geometric's Data format\n",
    "    pyg_graph = from_networkx(attributed_graph)\n",
    "    \n",
    "    # add the max degree as the graph label\n",
    "    pyg_graph.y = torch.tensor([max(dict(attributed_graph.degree()).values())])\n",
    "    \n",
    "    return pyg_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29790d86-2986-4d6d-aa3d-8a0ca91e43f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/lfesser/.conda/envs/borf/lib/python3.9/site-packages/torch_geometric/utils/convert.py:249: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  data[key] = torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "# max degree task on complete graphs\n",
    "\n",
    "random_integers = np.random.randint(10, 101, size=250)\n",
    "graphs = [generate_max_degree_graph(num_nodes=nodes, topology='ER', feature_dim=10) for nodes in random_integers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "269248a7-5e33-493c-b851-463bb8f3bdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 1287.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoding = \"LDP\"\n",
    "\n",
    "for i in tqdm(range(len(graphs))):\n",
    "    if encoding == \"LAPE\":\n",
    "        num_nodes = dataset[i].num_nodes\n",
    "        eigvecs = np.min([num_nodes, 8]) - 2\n",
    "        transform = T.AddLaplacianEigenvectorPE(k=eigvecs)\n",
    "\n",
    "    elif encoding == \"RWPE\":\n",
    "        transform = T.AddRandomWalkPE(walk_length=16)\n",
    "\n",
    "    elif encoding == \"LDP\":\n",
    "        transform = T.LocalDegreeProfile()\n",
    "\n",
    "    elif encoding == \"SUB\":\n",
    "        transform = T.RootedRWSubgraph(walk_length=10)\n",
    "\n",
    "    elif encoding == \"EGO\":\n",
    "        transform = T.RootedEgoNets(num_hops=2)\n",
    "\n",
    "    elif encoding == \"VN\":\n",
    "        transform = T.VirtualNode()\n",
    "        \n",
    "    graphs[i] = transform(graphs[i])\n",
    "    \n",
    "print(\"Feature Dimension: \", graphs[0].x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b689342c-07eb-40cc-8de1-e0d1c84d38f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555.1316328125\n"
     ]
    }
   ],
   "source": [
    "test_dataset = graphs\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "test_mae = test(test_loader, model, device, optimizer)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d846fc7-c2a5-48ed-9708-445e748c3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"synthetic_data/shortest_path_task/tree_graphs.pkl\"\n",
    "\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(graphs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362f2593-1bfb-4f3e-b2c8-c939ca8c9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topologies\n",
    "\n",
    "def create_complete_graph(num_nodes: int) -> nx.graph:\n",
    "    complete_graph = nx.complete_graph(num_nodes).to_undirected()\n",
    "    return complete_graph\n",
    "\n",
    "def create_path_graph(num_nodes: int) -> nx.Graph:\n",
    "    path_graph = nx.path_graph(num_nodes)\n",
    "    return path_graph\n",
    "\n",
    "def create_cycle_graph(num_nodes: int) -> nx.Graph:\n",
    "    cycle_graph = nx.cycle_graph(num_nodes)\n",
    "    return cycle_graph\n",
    "\n",
    "def create_4_regular_grid_graph(rows: int, cols: int) -> nx.Graph:    \n",
    "    grid_graph = nx.grid_2d_graph(rows, cols, periodic=True)  # Wraps around for 4-regular structure\n",
    "    grid_graph =  nx.convert_node_labels_to_integers(grid_graph)\n",
    "    for node in grid_graph.nodes:\n",
    "        grid_graph.nodes[node].clear()\n",
    "    return grid_graph\n",
    "\n",
    "def create_binary_tree(num_nodes: int) -> nx.Graph:\n",
    "    max_depth = math.ceil(math.log2(num_nodes + 1)) - 1\n",
    "    tree = nx.balanced_tree(r=2, h=max_depth)    \n",
    "    return tree\n",
    "\n",
    "def create_er_graph(num_nodes, probability=0.5):\n",
    "    G = nx.erdos_renyi_graph(n=num_nodes, p=probability)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0a9dee9-013d-4c16-a5bf-9e0bc31fa86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node feature distributions\n",
    "\n",
    "def add_gaussian_node_features(G: nx.graph, k: int) -> nx.graph:\n",
    "    mean = np.zeros(k)\n",
    "    cov = np.eye(k)\n",
    "\n",
    "    for node in G.nodes():\n",
    "        G.nodes[node]['x'] = np.random.multivariate_normal(mean, cov)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a987e-ed73-4ae1-9b85-0446f0b51215",
   "metadata": {},
   "source": [
    "## Train an example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e00842e-71bc-40d9-95d9-0790ce98a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torch import Tensor\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "def max_pool(x: Tensor, batch: Optional[Tensor],\n",
    "                    size: Optional[int] = None) -> Tensor:\n",
    "    dim = -1 if isinstance(x, Tensor) and x.dim() == 1 else -2\n",
    "\n",
    "    if batch is None:\n",
    "        return x.max(dim=dim, keepdim=x.dim() <= 2)[0]\n",
    "    return scatter(x, batch, dim=dim, dim_size=size, reduce='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f5fb4b3e-b947-40fe-a8b8-0fbbe15cc7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, channels, num_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_emb = Linear(15, channels)\n",
    "        self.pe_norm = BatchNorm1d(20)\n",
    "        self.edge_emb = Linear(3, channels)\n",
    "        \n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = GCNConv(channels, channels, normalize=True)\n",
    "            self.convs.append(conv)       \n",
    "            \n",
    "        self.mlp = Sequential(\n",
    "            # Linear(channels, channels),\n",
    "            # ReLU(),\n",
    "            # Linear(channels, channels // 2),\n",
    "            # ReLU(),\n",
    "            # Linear(channels // 2, channels // 4),\n",
    "            # ReLU(),\n",
    "            Linear(channels, 1),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # dropout = Dropout(0.5)\n",
    "        x = x.float()\n",
    "        x = self.node_emb(x.squeeze(-1))\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            # x = dropout(x)\n",
    "        x = global_add_pool(x, batch)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1726a0f8-a8e5-4cbf-8d85-89ada591af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, device, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # model.redraw_projection.redraw_projections()\n",
    "        # out = model(data.x, data.pe, data.edge_index, data.edge_attr, data.batch)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        loss = (out.squeeze() - data.y).abs().mean()\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader, model, device, optimizer):\n",
    "    model.eval()\n",
    "\n",
    "    total_error = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        # out = model(data.x, data.pe, data.edge_index, data.edge_attr, data.batch)\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "        total_error += (out.squeeze() - data.y).abs().sum().item()\n",
    "    return total_error / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9aa87db2-9809-4941-adcb-547b546f48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(channels=32, num_layers=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10,\n",
    "                              min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d0a6f397-eb3a-4ccf-9d49-5efd949c6dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = graphs[:500]\n",
    "val_dataset = graphs[500:750]\n",
    "test_dataset = graphs[750:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5d13278f-0252-41d1-b859-fb6a0346ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d796a595-ae0b-49fe-9357-e168775fb162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.0067, Val: 0.0049, Test: 0.0049\n",
      "Epoch: 02, Loss: 0.0033, Val: 0.0042, Test: 0.0043\n",
      "Epoch: 03, Loss: 0.0036, Val: 0.0044, Test: 0.0045\n",
      "Epoch: 04, Loss: 0.0026, Val: 0.0029, Test: 0.0029\n",
      "Epoch: 05, Loss: 0.0029, Val: 0.0029, Test: 0.0029\n",
      "Epoch: 06, Loss: 0.0041, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 07, Loss: 0.0037, Val: 0.0043, Test: 0.0044\n",
      "Epoch: 08, Loss: 0.0033, Val: 0.0032, Test: 0.0031\n",
      "Epoch: 09, Loss: 0.0029, Val: 0.0048, Test: 0.0048\n",
      "Epoch: 10, Loss: 0.0034, Val: 0.0036, Test: 0.0036\n",
      "Epoch: 11, Loss: 0.0030, Val: 0.0038, Test: 0.0038\n",
      "Epoch: 12, Loss: 0.0028, Val: 0.0029, Test: 0.0029\n",
      "Epoch: 13, Loss: 0.0029, Val: 0.0052, Test: 0.0054\n",
      "Epoch: 14, Loss: 0.0039, Val: 0.0044, Test: 0.0043\n",
      "Epoch: 15, Loss: 0.0031, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 16, Loss: 0.0029, Val: 0.0030, Test: 0.0030\n",
      "Epoch: 17, Loss: 0.0028, Val: 0.0030, Test: 0.0031\n",
      "Epoch: 18, Loss: 0.0030, Val: 0.0040, Test: 0.0040\n",
      "Epoch: 19, Loss: 0.0029, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 20, Loss: 0.0029, Val: 0.0036, Test: 0.0036\n",
      "Epoch: 21, Loss: 0.0025, Val: 0.0029, Test: 0.0030\n",
      "Epoch: 22, Loss: 0.0024, Val: 0.0028, Test: 0.0029\n",
      "Epoch: 23, Loss: 0.0032, Val: 0.0041, Test: 0.0041\n",
      "Epoch: 24, Loss: 0.0034, Val: 0.0047, Test: 0.0048\n",
      "Epoch: 25, Loss: 0.0037, Val: 0.0033, Test: 0.0032\n",
      "Epoch: 26, Loss: 0.0025, Val: 0.0029, Test: 0.0030\n",
      "Epoch: 27, Loss: 0.0029, Val: 0.0042, Test: 0.0041\n",
      "Epoch: 28, Loss: 0.0035, Val: 0.0035, Test: 0.0034\n",
      "Epoch: 29, Loss: 0.0031, Val: 0.0047, Test: 0.0047\n",
      "Epoch: 30, Loss: 0.0033, Val: 0.0043, Test: 0.0044\n",
      "Epoch: 31, Loss: 0.0039, Val: 0.0032, Test: 0.0031\n",
      "Epoch: 32, Loss: 0.0035, Val: 0.0044, Test: 0.0045\n",
      "Epoch: 33, Loss: 0.0036, Val: 0.0038, Test: 0.0039\n",
      "Epoch: 34, Loss: 0.0035, Val: 0.0035, Test: 0.0034\n",
      "Epoch: 35, Loss: 0.0028, Val: 0.0034, Test: 0.0034\n",
      "Epoch: 36, Loss: 0.0025, Val: 0.0027, Test: 0.0027\n",
      "Epoch: 37, Loss: 0.0024, Val: 0.0029, Test: 0.0030\n",
      "Epoch: 38, Loss: 0.0025, Val: 0.0029, Test: 0.0030\n",
      "Epoch: 39, Loss: 0.0028, Val: 0.0028, Test: 0.0028\n",
      "Epoch: 40, Loss: 0.0031, Val: 0.0031, Test: 0.0030\n",
      "Epoch: 41, Loss: 0.0027, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 42, Loss: 0.0028, Val: 0.0035, Test: 0.0035\n",
      "Epoch: 43, Loss: 0.0027, Val: 0.0027, Test: 0.0028\n",
      "Epoch: 44, Loss: 0.0025, Val: 0.0029, Test: 0.0029\n",
      "Epoch: 45, Loss: 0.0025, Val: 0.0028, Test: 0.0028\n",
      "Epoch: 46, Loss: 0.0027, Val: 0.0047, Test: 0.0047\n",
      "Epoch: 47, Loss: 0.0033, Val: 0.0032, Test: 0.0031\n",
      "Epoch: 48, Loss: 0.0028, Val: 0.0047, Test: 0.0048\n",
      "Epoch: 49, Loss: 0.0031, Val: 0.0030, Test: 0.0030\n",
      "Epoch: 50, Loss: 0.0024, Val: 0.0032, Test: 0.0031\n",
      "Epoch: 51, Loss: 0.0027, Val: 0.0034, Test: 0.0033\n",
      "Epoch: 52, Loss: 0.0029, Val: 0.0046, Test: 0.0047\n",
      "Epoch: 53, Loss: 0.0037, Val: 0.0035, Test: 0.0033\n",
      "Epoch: 54, Loss: 0.0034, Val: 0.0036, Test: 0.0035\n",
      "Epoch: 55, Loss: 0.0030, Val: 0.0033, Test: 0.0031\n",
      "Epoch: 56, Loss: 0.0029, Val: 0.0034, Test: 0.0034\n",
      "Epoch: 57, Loss: 0.0028, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 58, Loss: 0.0032, Val: 0.0033, Test: 0.0032\n",
      "Epoch: 59, Loss: 0.0029, Val: 0.0037, Test: 0.0037\n",
      "Epoch: 60, Loss: 0.0031, Val: 0.0036, Test: 0.0037\n",
      "Epoch: 61, Loss: 0.0029, Val: 0.0034, Test: 0.0034\n",
      "Epoch: 62, Loss: 0.0033, Val: 0.0041, Test: 0.0043\n",
      "Epoch: 63, Loss: 0.0034, Val: 0.0041, Test: 0.0040\n",
      "Epoch: 64, Loss: 0.0031, Val: 0.0035, Test: 0.0035\n",
      "Epoch: 65, Loss: 0.0026, Val: 0.0034, Test: 0.0034\n",
      "Epoch: 66, Loss: 0.0028, Val: 0.0032, Test: 0.0033\n",
      "Epoch: 67, Loss: 0.0030, Val: 0.0036, Test: 0.0036\n",
      "Epoch: 68, Loss: 0.0029, Val: 0.0034, Test: 0.0034\n",
      "Epoch: 69, Loss: 0.0030, Val: 0.0033, Test: 0.0034\n",
      "Epoch: 70, Loss: 0.0032, Val: 0.0033, Test: 0.0032\n",
      "Epoch: 71, Loss: 0.0028, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 72, Loss: 0.0028, Val: 0.0037, Test: 0.0038\n",
      "Epoch: 73, Loss: 0.0032, Val: 0.0035, Test: 0.0036\n",
      "Epoch: 74, Loss: 0.0030, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 75, Loss: 0.0026, Val: 0.0028, Test: 0.0028\n",
      "Epoch: 76, Loss: 0.0027, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 77, Loss: 0.0028, Val: 0.0029, Test: 0.0030\n",
      "Epoch: 78, Loss: 0.0028, Val: 0.0030, Test: 0.0030\n",
      "Epoch: 79, Loss: 0.0030, Val: 0.0043, Test: 0.0043\n",
      "Epoch: 80, Loss: 0.0030, Val: 0.0030, Test: 0.0030\n",
      "Epoch: 81, Loss: 0.0027, Val: 0.0040, Test: 0.0040\n",
      "Epoch: 82, Loss: 0.0028, Val: 0.0032, Test: 0.0033\n",
      "Epoch: 83, Loss: 0.0026, Val: 0.0030, Test: 0.0031\n",
      "Epoch: 84, Loss: 0.0028, Val: 0.0035, Test: 0.0035\n",
      "Epoch: 85, Loss: 0.0030, Val: 0.0029, Test: 0.0029\n",
      "Epoch: 86, Loss: 0.0026, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 87, Loss: 0.0028, Val: 0.0032, Test: 0.0032\n",
      "Epoch: 88, Loss: 0.0038, Val: 0.0035, Test: 0.0034\n",
      "Epoch: 89, Loss: 0.0032, Val: 0.0036, Test: 0.0035\n",
      "Epoch: 90, Loss: 0.0031, Val: 0.0031, Test: 0.0031\n",
      "Epoch: 91, Loss: 0.0031, Val: 0.0031, Test: 0.0032\n",
      "Epoch: 92, Loss: 0.0028, Val: 0.0036, Test: 0.0036\n",
      "Epoch: 93, Loss: 0.0030, Val: 0.0038, Test: 0.0039\n",
      "Epoch: 94, Loss: 0.0029, Val: 0.0029, Test: 0.0029\n",
      "Epoch: 95, Loss: 0.0023, Val: 0.0036, Test: 0.0037\n",
      "Epoch: 96, Loss: 0.0028, Val: 0.0038, Test: 0.0037\n",
      "Epoch: 97, Loss: 0.0028, Val: 0.0029, Test: 0.0028\n",
      "Epoch: 98, Loss: 0.0027, Val: 0.0038, Test: 0.0039\n",
      "Epoch: 99, Loss: 0.0030, Val: 0.0034, Test: 0.0035\n",
      "Epoch: 100, Loss: 0.0025, Val: 0.0029, Test: 0.0030\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader, model, device, optimizer)\n",
    "    val_mae = test(val_loader, model, device, optimizer)\n",
    "    test_mae = test(test_loader, model, device, optimizer)\n",
    "    scheduler.step(val_mae)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_mae:.4f}, '\n",
    "          f'Test: {test_mae:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "borf_2",
   "language": "python",
   "name": "borf_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
